{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOfHXkzKsMYq8vZaIi5/SJS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## VGGNet\n","VGGNet是通过简单堆叠卷积构建网络的巅峰之作。\n","\n","VGGNet是由牛津大学的Visual Geometry Group提出的一种结构，该架构获得了2014年ILSVRC分类任务的亚军以及定位任务的冠军。它的实质是使用了比AlexNet更小的卷积核与更深的网络。在这里，我们将试图实现VGGNet16。"],"metadata":{"id":"aVX-l0ess_PZ"}},{"cell_type":"markdown","source":["VGGNet16的架构为：输入层、卷积层、卷积层、池化层、卷积层、卷积层、池化层、卷积层、卷积层、卷积层、池化层、卷积层、卷积层、卷积层、池化层、卷积层、卷积层、卷积层、池化层、全连接层、全连接层、全连接层、输出层。"],"metadata":{"id":"aB1GnhLBuogt"}},{"cell_type":"markdown","source":["### 1. 导入必要模块"],"metadata":{"id":"evKvsiQb3JR5"}},{"cell_type":"code","source":["import time as time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"u8p3iT51Kp1_","executionInfo":{"status":"ok","timestamp":1701016024627,"user_tz":-480,"elapsed":2651,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### 2. 引入数据集\n","\n","在这里，我们直接使用tensorflow中自带的数据集。"],"metadata":{"id":"zVHs-d4v3jEj"}},{"cell_type":"code","source":["# These variables are all in type of numpy.\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","print(train_images.shape)\n","print(train_labels.shape)\n","print(test_images.shape)\n","print(test_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwtLPw8n3igq","executionInfo":{"status":"ok","timestamp":1701016025115,"user_tz":-480,"elapsed":494,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}},"outputId":"25442a21-a161-4a84-c688-58ef783ad60a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","(60000, 28, 28)\n","(60000,)\n","(10000, 28, 28)\n","(10000,)\n"]}]},{"cell_type":"markdown","source":["### 3. 数据预处理\n","\n","将28\\*28的图片填充到32\\*32的规模，以便于进行输入。将图片变为3维，以便于神经网络的训练。同时，将分类变为one-hot编码，以便于后续在神经网络训练中可以使用categorical cross-entropy损失函数。"],"metadata":{"id":"8IPeJ2Cs47Xr"}},{"cell_type":"code","source":["train_images_32 = np.zeros((60000, 32, 32), dtype=train_images.dtype)\n","test_images_32 = np.zeros((10000, 32, 32), dtype=test_images.dtype)\n","\n","start_row = (32 - 28) // 2\n","start_col = (32 - 28) // 2\n","for i in range(60000):\n","  train_images_32[i][start_row:start_row+28, start_col:start_col+28] = train_images[i]\n","for i in range(10000):\n","  test_images_32[i][start_row:start_row+28, start_col:start_col+28] = test_images[i]\n","\n","train_images_32 = train_images_32.reshape((60000, 32, 32, 1)).astype('float32') / 255\n","test_images_32 = test_images_32.reshape((10000, 32, 32, 1)).astype('float32') / 255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","print(train_images_32.shape)\n","print(test_images_32.shape)\n","print(train_labels.shape)\n","print(test_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15yEJlHs3wgd","executionInfo":{"status":"ok","timestamp":1701016025508,"user_tz":-480,"elapsed":396,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}},"outputId":"e35680ae-f64a-4bc8-a35a-1aad36aaa03c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 32, 32, 1)\n","(10000, 32, 32, 1)\n","(60000, 10)\n","(10000, 10)\n"]}]},{"cell_type":"markdown","source":["### 4. 搭建神经网络"],"metadata":{"id":"wi0ezLgXlvx6"}},{"cell_type":"code","source":["model = models.Sequential()\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","# model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(layers.Flatten())\n","# model.add(layers.Dense(4096, activation='relu'))\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))"],"metadata":{"id":"zS9GozxPvKBw","executionInfo":{"status":"ok","timestamp":1701016028874,"user_tz":-480,"elapsed":3368,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### 5. 编译模型"],"metadata":{"id":"da2HNvNrc5SA"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"XwQrIa57yE8v","executionInfo":{"status":"ok","timestamp":1701016028874,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### 6. 训练模型"],"metadata":{"id":"eLmd2aTqc7k0"}},{"cell_type":"code","source":["start_time = time.time()\n","model.fit(train_images_32, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n","end_time = time.time()\n","print(\"Running time:\", end_time - start_time, \"seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJYDMudiyFw8","executionInfo":{"status":"ok","timestamp":1701016173073,"user_tz":-480,"elapsed":144202,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}},"outputId":"1bc2f148-991f-43c1-dc4d-f1bb9a9e6b96"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","750/750 [==============================] - 33s 28ms/step - loss: 2.3015 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1060\n","Epoch 2/5\n","750/750 [==============================] - 21s 28ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3019 - val_accuracy: 0.1060\n","Epoch 3/5\n","750/750 [==============================] - 19s 26ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Epoch 4/5\n","750/750 [==============================] - 19s 26ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n","Epoch 5/5\n","750/750 [==============================] - 19s 26ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n","Running time: 143.9748764038086 seconds\n"]}]},{"cell_type":"markdown","source":["### 7. 模型用于测试集"],"metadata":{"id":"2uEdasLjc95Z"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images_32, test_labels)\n","print(f'Test accuracy: {test_acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcNqclyhyGzy","executionInfo":{"status":"ok","timestamp":1700848870842,"user_tz":-480,"elapsed":2963,"user":{"displayName":"Ryan Lee","userId":"10453969434458798382"}},"outputId":"bd745f2d-7ccb-4293-c43f-4f3370551cea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 7ms/step - loss: 0.0433 - accuracy: 0.9905\n","Test accuracy: 0.9904999732971191\n"]}]}]}