{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 当代人工智能实验一：文本分类\n",
    "## ——Word2Vec & Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 一. 引入必要模块\n",
    "numpy将用于数据的处理。\n",
    "gensim用于实现Word2Vec。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 打开并读取训练数据文档\n",
    "f_train = open('train_data.txt')\n",
    "train_text = f_train.read()\n",
    "# print(train_text)\n",
    "# 观察数据特征，确定数据文档中的每一项均由一个回车分割，故采取切片\n",
    "train_text = train_text.split(\"\\n\")\n",
    "# 创造两个数组，存储训练数据\n",
    "# labelList 存储每个数据的标签\n",
    "# rawList 存储每个数据的文本内容\n",
    "labelList = []\n",
    "rawList = []\n",
    "for i in range(len(train_text)-1):\n",
    "    train_text[i] = eval(train_text[i])\n",
    "    labelList.append(train_text[i][\"label\"])\n",
    "    rawList.append(train_text[i][\"raw\"])\n",
    "labelList = np.array(labelList)\n",
    "rawList = np.array(rawList)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 打开并读取测试数据文档\n",
    "f_test = open('test.txt')\n",
    "result = f_test.read()\n",
    "# print(test_text)\n",
    "# 观察数据特征，确定数据文档中的每一项均由一个回车分割，故采取切片\n",
    "result = result.split(\"\\n\")\n",
    "# 去除第一行\n",
    "result.pop(0)\n",
    "# 测试集的大小\n",
    "TEST_LENGTH = 2000\n",
    "result_id = list(range(TEST_LENGTH))\n",
    "result_text = []\n",
    "for i in range(TEST_LENGTH):\n",
    "    comma_index = result[i].find(\",\")\n",
    "    if comma_index != -1:\n",
    "        result_text.append(result[i][comma_index+2:])\n",
    "    else:\n",
    "        print(\"ERROR: COMMA NOT FOUND\")\n",
    "result_text = np.array(result_text)\n",
    "# result_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ALL = np.append(rawList, result_text)\n",
    "# 记录数据的个数\n",
    "LENGTH_TRAIN = len(rawList)\n",
    "LENGTH_ALL = len(ALL)\n",
    "# ALL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.02979541, -0.08766242,  0.08342204, ..., -0.38438728,\n        -0.17758617,  0.2699404 ],\n       [-0.04600288, -0.13039319,  0.24081647, ..., -0.58374388,\n        -0.24104959,  0.32365268],\n       [-0.24457299,  0.06303147,  0.02581426, ..., -0.33066293,\n         0.00376713,  0.26012252],\n       ...,\n       [-0.10570819,  0.14229903, -0.05444292, ..., -0.38411804,\n        -0.03611981,  0.46095462],\n       [-0.31930256,  0.00304263,  0.1257138 , ..., -0.37763401,\n        -0.02791453,  0.41959502],\n       [ 0.12610122, -0.27173106,  0.19307734, ..., -0.27767938,\n         0.18830031,  0.13073176]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts = [word_tokenize(text.lower()) for text in rawList]\n",
    "model = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=1, sg=0)\n",
    "text_vectors = []\n",
    "for tokenized_text in tokenized_texts:\n",
    "    text_vector = np.zeros(model.vector_size)\n",
    "    word_count = 0\n",
    "\n",
    "    for word in tokenized_text:\n",
    "        if word in model.wv:\n",
    "            text_vector = text_vector + model.wv[word]\n",
    "            word_count = word_count + 1\n",
    "\n",
    "    if word_count > 0:\n",
    "        text_vector = text_vector / word_count\n",
    "\n",
    "    text_vectors.append(text_vector)\n",
    "\n",
    "text_vectors = np.array(text_vectors)\n",
    "text_vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
