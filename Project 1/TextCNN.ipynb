{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 当代人工智能实验一：文本分类\n",
    "## ——TF-IDF & TextCNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 一. 引入必要模块\n",
    "numpy将用于数据的处理。\n",
    "time用于记录代码运行时间。\n",
    "train_test_split用于进行训练集与验证集的划分。\n",
    "tensorflow.keras用于进行Tokenizer分词与TextCNN的训练。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 二. 载入数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "y = np.load('labelList.npy') # 标签\n",
    "X = np.load('textVectorList.npy') # 向量化的文字"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 三. 利用训练集数据训练TF-IDF下的TextCNN模型\n",
    "使用tensorflow.keras中的Sequential模块。\n",
    "在这里，我们通过交叉验证来验证模型的正确性。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "219/219 [==============================] - 233s 1s/step - loss: 2.2308 - accuracy: 0.1193 - val_loss: 4.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 223s 1s/step - loss: 2.1904 - accuracy: 0.1381 - val_loss: 5.2808 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 222s 1s/step - loss: 2.1770 - accuracy: 0.1487 - val_loss: 5.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 226s 1s/step - loss: 2.1656 - accuracy: 0.1533 - val_loss: 6.3031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 227s 1s/step - loss: 2.1584 - accuracy: 0.1580 - val_loss: 6.6824 - val_accuracy: 0.0000e+00\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 2.7198 - accuracy: 0.1406\n",
      "精确度为: 0.140625\n",
      "运行时间为: 1215.3077547550201\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, 5, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# 训练模型\n",
    "model.fit(X.reshape(X.shape[0], X.shape[1], 1), y, epochs=5, validation_split=0.125)\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(X.reshape(X.shape[0], X.shape[1], 1), y)\n",
    "end_time = time.time()\n",
    "print(\"精确度为:\", accuracy)\n",
    "print(\"运行时间为:\", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们发现，运行速度极其缓慢，且精确度也极低。这可能是因为TF-IDF的向量维度过高，且TF-IDF矩阵过于稀疏导致的。\n",
    "在这里，我们尝试使用keras模块中的Tokenizer分词器进行分词与向量映射。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X = np.load(\"rawList.npy\") # 文字\n",
    "Y = np.load(\"labelList.npy\") # 标签"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "219/219 [==============================] - 24s 107ms/step - loss: 1.5172 - accuracy: 0.5624 - val_loss: 0.5690 - val_accuracy: 0.8300\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 21s 97ms/step - loss: 0.3892 - accuracy: 0.8781 - val_loss: 0.3243 - val_accuracy: 0.8900\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 21s 96ms/step - loss: 0.1513 - accuracy: 0.9594 - val_loss: 0.2465 - val_accuracy: 0.9080\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 21s 95ms/step - loss: 0.0482 - accuracy: 0.9933 - val_loss: 0.2257 - val_accuracy: 0.9210\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 22s 99ms/step - loss: 0.0180 - accuracy: 0.9987 - val_loss: 0.2176 - val_accuracy: 0.9280\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2176 - accuracy: 0.9280\n",
      "精确度为: 0.9279999732971191\n",
      "运行时间为: 110.25250554084778\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# 将文本转换为序列\n",
    "# 设置词汇表大小\n",
    "max_words = 50000\n",
    "# 设置向量最大长度\n",
    "maxlen = 200\n",
    "# 使用Tokenizer进行文本转换为向量的操作\n",
    "# 可以过滤大量标点符号\n",
    "tokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.125, random_state=42)\n",
    "# 构建模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "end_time = time.time()\n",
    "print(\"精确度为:\", accuracy)\n",
    "print(\"运行时间为:\", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "观察到，运行时间大幅度减少，且精确度较高，可以到约93%的水平。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 四. 预测测试集结果\n",
    "预测并观察最终的结果。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# 载入测试集\n",
    "new_data = np.load(\"result_text.npy\")\n",
    "new_sequences = tokenizer.texts_to_sequences(new_data)\n",
    "new_X = pad_sequences(new_sequences, maxlen=maxlen)\n",
    "\n",
    "# 使用训练好的模型进行预测\n",
    "predictions = model.predict(new_X)\n",
    "\n",
    "# 如果模型是多类别分类的，你可能需要将预测的结果转换成类别标签\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6, 4, 4, ..., 9, 6, 9], dtype=int64)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
